% !TeX root = ../main.tex

\chapter{绪论}

\section{主要研究内容}
随着异构计算的发展和人工智能技术的广泛应用，如何将各种神经网络模型高效地部署到不同架构的设备上正逐渐成为研究的热点\cite{DLcompiler}。
为解决这一问题，研究人员将传统的编译方法与人工智能技术相结合，设计出一系列的深度学习编译器，并将它们集成到深度学习框架中。

由于不同的目标硬件具有不同的体系结构特点，编译器需要针对目标硬件进行编译优化配置的搜索，尝试不同的配置参数，并获得相应程序的运行时间。
但是，当神经网络计算图的规模很大时，每次运行程序所需的时间也很长，使得编译器无法快速搜索得到最优参数配置。

为解决此问题，深度学习编译器内置了耗时模型（Cost Model），用于在不真正运行程序的前提下，估计出不同编译配置对应的运行时间。
传统的耗时模型是由专家根据计算图特征和硬件架构手工推导耗时估计的公式，准确率不高，而且针对不同的硬件需要进行不同的设计，可扩展性差。

Halide \cite{Adams2019LearningTO} 和 TVM \cite{DBLP:journals/corr/abs-1805-08166} 等团队提出了一系列基于机器学习的耗时模型。
通过提取神经网络程序的特征，将其输入耗时模型中，得到耗时的估计值，并与实际耗时相比较，计算损失函数，并进行反向传播更新模型的参数。这种基于机器学习的耗时估计方法
具有很强的通用性，可以应用在不同的目标硬件上。但它们的模型都是针对程序代码进行估计，未考虑计算图的拓扑结构信息，从而忽略了计算图结点之间可能的相互影响。

本文参考了一些利用计算图结构信息的耗时预测模型\cite{haikang} \cite{GCN2}  \cite{Alearned}，并在此基础上对模型结构进行了改进，取得了一定程度的提升。

\section{本文结构}
本文总共分为五章：

第一章为绪论，介绍了本文着重研究的计算图耗时预测问题。

第二章为研究现状，回顾了现有的计算图耗时预测方法，包括根据经验公式建立耗时模型的传统方法，使用 LSTM 的耗时预测模型和使用图神经网络的耗时预测模型。

第三章详细介绍了本文所使用的图神经网络耗时预测方法，包括针对图数据的分析和特征编码，以及具体模型结构、损失函数和评价指标的设计。

第四章为实验及结果分析，通过对比实验说明了本文所用的模型相对于其他模型在真实数据集上的提升。

第五章为全文的总结和对未来进一步研究的展望。